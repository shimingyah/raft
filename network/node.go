package network

import (
	"bytes"
	"context"
	"encoding/binary"
	"errors"
	"fmt"
	"math/rand"
	"sync"
	"time"

	"github.com/shimingyah/raft"
	pb "github.com/shimingyah/raft/raftpb"
	"github.com/sirupsen/logrus"
)

var (
	ErrDuplicateRaftId = errors.New("Node is already part of group")
	ErrNoNode          = errors.New("No node has been set up yet")
	errInternalRetry   = errors.New("Retry proposal again")
)

// Node raft node
type Node struct {
	// Used to keep track of lin read requests.
	requestCh chan linReadReq

	// raft conf state
	confState *pb.ConfState

	// raft node
	raft raft.Node

	// fields which are nevew changed after init.
	Cfg *raft.Config

	// node address
	Addr string

	// raft id
	ID uint64

	// raft peers
	peers map[uint64]string

	// conf changes
	confChanges map[uint64]chan error

	// send msg to batch buffered
	messages chan sendmsg

	// raft context used for add node...
	RaftContext *pb.Context

	// raft log where to store
	Store *raft.DiskStorage

	Proposals proposals

	// random generate conf changed id
	Rand *rand.Rand

	sync.RWMutex
}

// NewNode create raft node
func NewNode(rc *pb.Context, store *raft.DiskStorage) *Node {
	snap, err := store.Snapshot()
	raft.Check(err)

	n := &Node{
		ID:    rc.Id,
		Addr:  rc.Addr,
		Store: store,
		Rand:  rand.New(rand.NewSource(time.Now().UnixNano())),
		Cfg: &raft.Config{
			ID:              rc.Id,
			ElectionTick:    100, // 200 ms if we call Tick() every 20 ms.
			HeartbeatTick:   1,   // 20 ms if we call Tick() every 20 ms.
			Storage:         store,
			MaxSizePerMsg:   256 << 10,
			MaxInflightMsgs: 256,
			// We don't need lease based reads. They cause issues because they
			// require CheckQuorum to be true, and that causes a lot of issues
			// for us during cluster bootstrapping and later. A seemingly
			// healthy cluster would just cause leader to step down due to
			// "inactive" quorum, and then disallow anyone from becoming leader.
			// So, let's stick to default options.  Let's achieve correctness,
			// then we achieve performance. Plus, for the Dgraph alphas, we'll
			// be soon relying only on Timestamps for blocking reads and
			// achieving linearizability, than checking quorums (Zero would
			// still check quorums).
			ReadOnlyOption: raft.ReadOnlySafe,
			// When a disconnected node joins back, it forces a leader change,
			// as it starts with a higher term, as described in Raft thesis (not
			// the paper) in section 9.6. This setting can avoid that by only
			// increasing the term, if the node has a good chance of becoming
			// the leader.
			PreVote: true,

			// We can explicitly set Applied to the first index in the Raft log,
			// so it does not derive it separately, thus avoiding a crash when
			// the Applied is set to below snapshot index by Raft.
			// In case this is a new Raft log, first would be 1, and therefore
			// Applied would be zero, hence meeting the condition by the library
			// that Applied should only be set during a restart.
			//
			// Update: Set the Applied to the latest snapshot, because it seems
			// like somehow the first index can be out of sync with the latest
			// snapshot.
			Applied: snap.Metadata.Index,

			Logger: &raftLogger{},
		},
	}

	return n
}

// SetRaft would set the provided raft.Node to this node.
// It would check fail if the node is already set.
func (n *Node) SetRaft(r raft.Node) {
	n.Lock()
	defer n.Unlock()
	raft.AssertTrue(n.raft == nil)
	n.raft = r
}

// Raft would return back the raft.Node stored in the node.
func (n *Node) Raft() raft.Node {
	n.RLock()
	defer n.RUnlock()
	return n.raft
}

// SetConfState would store the latest ConfState generated by ApplyConfChange.
func (n *Node) SetConfState(cs *pb.ConfState) {
	n.Lock()
	defer n.Unlock()
	n.confState = cs
}

// ConfState would return the latest ConfState stored in node.
func (n *Node) ConfState() *pb.ConfState {
	n.RLock()
	defer n.RUnlock()
	return n.confState
}

func (n *Node) storeConfChange(che chan error) uint64 {
	n.Lock()
	defer n.Unlock()
	id := rand.Uint64()
	_, has := n.confChanges[id]
	for has {
		id = rand.Uint64()
		_, has = n.confChanges[id]
	}
	n.confChanges[id] = che
	return id
}

// DoneConfChange finish conf change
func (n *Node) DoneConfChange(id uint64, err error) {
	n.Lock()
	defer n.Unlock()
	ch, has := n.confChanges[id]
	if !has {
		return
	}
	delete(n.confChanges, id)
	ch <- err
}

// SetPeer addr must not be empty.
func (n *Node) SetPeer(pid uint64, addr string) {
	raft.AssertTruef(addr != "", "SetPeer for peer %d has empty addr.", pid)
	n.Lock()
	defer n.Unlock()
	n.peers[pid] = addr
}

// DeletePeer remove peer by pid
func (n *Node) DeletePeer(pid uint64) {
	if pid == n.ID {
		return
	}

	n.Lock()
	defer n.Unlock()
	delete(n.peers, pid)
}

// Peer return peer address by pid
func (n *Node) Peer(pid uint64) (string, bool) {
	n.RLock()
	defer n.RUnlock()
	addr, ok := n.peers[pid]
	return addr, ok
}

// Send msg to message channel, wait for batch send.
func (n *Node) Send(m pb.Message) {
	raft.AssertTruef(n.ID != m.To, "Sending message to itself")
	data, err := m.Marshal()
	raft.Check(err)

	// As long as leadership is stable, any attempted Propose() calls should be reflected in the
	// next raft.Ready.Messages. Leaders will send MsgApps to the followers; followers will send
	// MsgProp to the leader. It is up to the transport layer to get those messages to their
	// destination. If a MsgApp gets dropped by the transport layer, it will get retried by raft
	// (i.e. it will appear in a future Ready.Messages), but MsgProp will only be sent once. During
	// leadership transitions, proposals may get dropped even if the network is reliable.
	//
	// We can't do a select default here. The messages must be sent to the channel, otherwise we
	// should block until the channel can accept these messages. BatchAndSendMessages would take
	// care of dropping messages which can't be sent due to network issues to the corresponding
	// node. But, we shouldn't take the liberty to do that here. It would take us more time to
	// repropose these dropped messages anyway, than to block here a bit waiting for the messages
	// channel to clear out.
	n.messages <- sendmsg{to: m.To, data: data}
}

// Snapshot return raft snapshot
func (n *Node) Snapshot() (pb.Snapshot, error) {
	if n == nil || n.Store == nil {
		return pb.Snapshot{}, errors.New("Uninitialized node or raft store.")
	}
	return n.Store.Snapshot()
}

// Save waiting for commited log entry
func (n *Node) Save(h pb.HardState, es []pb.Entry, s pb.Snapshot) {
	raft.Check(n.Store.Save(h, es, s))
}

// PastLife return snapshot index
func (n *Node) PastLife() (idx uint64, restart bool, err error) {
	var sp pb.Snapshot
	sp, err = n.Store.Snapshot()
	if err != nil {
		return
	}
	if !raft.IsEmptySnap(sp) {
		raft.GetLogger().Infof("Found Snapshot.Metadata: %+v\n", sp.Metadata)
		restart = true
		idx = sp.Metadata.Index
	}

	var hd pb.HardState
	hd, err = n.Store.HardState()
	if err != nil {
		return
	}
	if !raft.IsEmptyHardState(hd) {
		raft.GetLogger().Infof("Found hardstate: %+v\n", hd)
		restart = true
	}

	var num int
	num, err = n.Store.NumEntries()
	if err != nil {
		return
	}
	raft.GetLogger().Infof("Group %d found %d entries\n", n.RaftContext.Group, num)
	// We'll always have at least one entry.
	if num > 1 {
		restart = true
	}
	return
}

// Connect the node and makes its peerPool refer to the constructed pool and address
// (possibly updating ourselves from the old address.)  (Unless pid is ourselves, in which
// case this does nothing.)
func (n *Node) Connect(pid uint64, addr string) {
	if pid == n.ID {
		return
	}
	if paddr, ok := n.Peer(pid); ok && paddr == addr {
		// Already connected.
		return
	}

	// Here's what we do.  Right now peerPool maps peer node id's to addr values.  If
	// a *pool can be created, good, but if not, we still create a peerPoolEntry with
	// a nil *pool.
	if addr == n.Addr {
		// TODO: Note this fact in more general peer health info somehow.
		raft.GetLogger().Infof("Peer %d claims same host as me\n", pid)
		n.SetPeer(pid, addr)
		return
	}

	Get().Connect(addr)
	n.SetPeer(pid, addr)
}

const (
	messageBatchLimitSize = 10 * 1024 * 1024
)

// BatchSendMessages buffed batch msg then send
func (n *Node) BatchSendMessages() {
	batches := make(map[uint64]*bytes.Buffer)
	failedConn := make(map[uint64]bool)

	for {
		totalSize := 0
		msg := <-n.messages

	slurp_loop:
		for {
			// get or new raft node buf
			var buf *bytes.Buffer
			if b, ok := batches[msg.to]; !ok {
				buf = new(bytes.Buffer)
				batches[msg.to] = buf
			} else {
				buf = b
			}

			// write data length(4B) and actual bytes.
			totalSize += 4 + len(msg.data)
			raft.Check(binary.Write(buf, binary.LittleEndian, uint32(len(msg.data))))
			raft.Check2(buf.Write(msg.data))

			if totalSize > messageBatchLimitSize {
				// We limit the batch size, but we aren't pushing back on
				// n.messages, because the loop below spawns a goroutine
				// to do its dirty work.  This is good because right now
				// (*node).send fails(!) if the channel is full.
				break
			}

			// if keep receiving msg, it will send to raft node buf
			// otherwise break batch loop, then send buffed msg.
			select {
			case msg = <-n.messages:
			default:
				break slurp_loop
			}
		}

		// send buffed batch msg
		for to, buf := range batches {
			if buf.Len() == 0 {
				continue
			}

			addr, has := n.Peer(to)
			pool, err := Get().Get(addr)
			if !has || err != nil {
				if exists := failedConn[to]; !exists {
					// So that we print error only the first time we are not able to connect.
					// Otherwise, the log is polluted with multiple errors.
					raft.GetLogger().Warningf("No healthy connection to node Id: %d addr: [%s], err: %v\n",
						to, addr, err)
					failedConn[to] = true
				}
				continue
			}

			failedConn[to] = false
			data := make([]byte, buf.Len())
			copy(data, buf.Bytes())
			go n.doSendMessage(pool, data)
			buf.Reset()
		}
	}
}

func (n *Node) doSendMessage(pool *Pool, data []byte) {
	ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)
	defer cancel()

	client := pool.Get()
	c := pb.NewRaftClient(client)
	p := pb.Payload{Data: data}
	batch := &pb.Batch{
		Context: *n.RaftContext,
		Payload: p,
	}

	// We don't need to run this in a goroutine, because doSendMessage is
	// already being run in one.
	if _, err := c.Send(ctx, batch); err != nil {
		raft.GetLogger().Infof("Error while sending Raft message to node with addr: %s, err: %v\n", pool.Addr, err)
	}
	// We don't need to do anything if we receive any error while sending message.
	// RAFT would automatically retry.
	return
}

func (n *Node) proposeConfChange(ctx context.Context, pb pb.ConfChange) error {
	cctx, cancel := context.WithTimeout(ctx, 3*time.Second)
	defer cancel()

	ch := make(chan error, 1)
	id := n.storeConfChange(ch)
	// TODO: Delete id from the map.
	pb.ID = id
	if err := n.Raft().ProposeConfChange(cctx, pb); err != nil {
		if cctx.Err() != nil {
			return errInternalRetry
		}
		raft.GetLogger().Warningf("Error while proposing conf change: %v", err)
		return err
	}

	select {
	case err := <-ch:
		return err
	case <-ctx.Done():
		return ctx.Err()
	case <-cctx.Done():
		return errInternalRetry
	}
}

// ProposePeerAdd add raft node
func (n *Node) ProposePeerAdd(ctx context.Context, id uint64) error {
	addr, ok := n.Peer(id)
	raft.AssertTruef(ok, "Unable to find conn pool for peer: %d", id)
	rc := &pb.Context{
		Addr:  addr,
		Group: n.RaftContext.Group,
		Id:    id,
	}

	rcBytes, err := rc.Marshal()
	raft.Check(err)

	cc := pb.ConfChange{
		Type:    pb.ConfChangeAddNode,
		NodeID:  id,
		Context: rcBytes,
	}
	err = errInternalRetry
	for err == errInternalRetry {
		raft.GetLogger().Infof("Trying to add %d to cluster. Addr: %v\n", id, addr)
		raft.GetLogger().Infof("Current confstate at %d: %+v\n", n.ID, n.ConfState())
		err = n.proposeConfChange(ctx, cc)
	}
	return err
}

// ProposePeerRemove remove raft node
func (n *Node) ProposePeerRemove(ctx context.Context, id uint64) error {
	if n.Raft() == nil {
		return ErrNoNode
	}
	if _, ok := n.Peer(id); !ok && id != n.RaftContext.Id {
		return fmt.Errorf("Node %d not part of group", id)
	}
	cc := pb.ConfChange{
		Type:   pb.ConfChangeRemoveNode,
		NodeID: id,
	}
	err := errInternalRetry
	for err == errInternalRetry {
		err = n.proposeConfChange(ctx, cc)
	}
	return err
}

type sendmsg struct {
	to   uint64
	data []byte
}

// ProposalCtx record propose result
type ProposalCtx struct {
	ErrCh chan error
	Ctx   context.Context
}

type proposals struct {
	all map[string]*ProposalCtx
	sync.RWMutex
}

// Store propose ctx
func (p *proposals) Store(key string, pctx *ProposalCtx) bool {
	if len(key) == 0 {
		return false
	}

	p.Lock()
	defer p.Unlock()
	if p.all == nil {
		p.all = make(map[string]*ProposalCtx)
	}
	if _, has := p.all[key]; has {
		return false
	}

	p.all[key] = pctx
	return true
}

// Get return propose ctx
func (p *proposals) Get(key string) *ProposalCtx {
	p.RLock()
	defer p.RUnlock()
	return p.all[key]
}

// Delete remove exist key's propose ctx
func (p *proposals) Delete(key string) {
	if len(key) == 0 {
		return
	}
	p.Lock()
	defer p.Unlock()
	delete(p.all, key)
}

// Done finish propose ctx
func (p *proposals) Done(key string, err error) {
	if len(key) == 0 {
		return
	}

	p.Lock()
	defer p.Unlock()
	pd, has := p.all[key]
	if !has {
		// If we assert here, there would be a race condition between a context
		// timing out, and a proposal getting applied immediately after. That
		// would cause assert to fail. So, don't assert.
		return
	}
	delete(p.all, key)
	pd.ErrCh <- err
}

type linReadReq struct {
	// A one-shot chan which we send a raft index upon.
	indexCh chan<- uint64
}

type raftLogger struct {
}

func (rl *raftLogger) Debug(v ...interface{})                   { logrus.Info(v...) }
func (rl *raftLogger) Debugf(format string, v ...interface{})   { logrus.Infof(format, v...) }
func (rl *raftLogger) Error(v ...interface{})                   { logrus.Error(v...) }
func (rl *raftLogger) Errorf(format string, v ...interface{})   { logrus.Errorf(format, v...) }
func (rl *raftLogger) Info(v ...interface{})                    { logrus.Info(v...) }
func (rl *raftLogger) Infof(format string, v ...interface{})    { logrus.Infof(format, v...) }
func (rl *raftLogger) Warning(v ...interface{})                 { logrus.Warning(v...) }
func (rl *raftLogger) Warningf(format string, v ...interface{}) { logrus.Warningf(format, v...) }
func (rl *raftLogger) Fatal(v ...interface{})                   { logrus.Fatal(v...) }
func (rl *raftLogger) Fatalf(format string, v ...interface{})   { logrus.Fatalf(format, v...) }
func (rl *raftLogger) Panic(v ...interface{})                   { logrus.Panic(v...) }
func (rl *raftLogger) Panicf(format string, v ...interface{})   { logrus.Panicf(format, v...) }
